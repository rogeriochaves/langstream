"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4945],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>d});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),u=p(n),m=r,d=u["".concat(l,".").concat(m)]||u[m]||h[m]||o;return n?a.createElement(d,s(s({ref:t},c),{},{components:n})):a.createElement(d,s({ref:t},c))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,s=new Array(o);s[0]=m;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[u]="string"==typeof e?e:r,s[1]=i;for(var p=2;p<o;p++)s[p]=n[p];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},8130:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>p});var a=n(7462),r=(n(7294),n(3905));const o={},s="Simple Bot with Weather Tool",i={unversionedId:"examples/weather-bot",id:"examples/weather-bot",title:"Simple Bot with Weather Tool",description:"Below is a code example of a bot you can talk too which has the ability of checking the weather, it has memory, it is using OpenAI functions, and it streams its outputs:",source:"@site/docs/examples/weather-bot.md",sourceDirName:"examples",slug:"/examples/weather-bot",permalink:"/litechain/docs/examples/weather-bot",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/examples/weather-bot.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Code Examples",permalink:"/litechain/docs/examples/"}},l={},p=[],c=(u="CodeOutputBlock",function(e){return console.warn("Component "+u+" was not imported, exported, or provided by MDXProvider as global scope"),(0,r.kt)("div",e)});var u;const h={toc:p},m="wrapper";function d(e){let{components:t,...n}=e;return(0,r.kt)(m,(0,a.Z)({},h,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"simple-bot-with-weather-tool"},"Simple Bot with Weather Tool"),(0,r.kt)("p",null,"Below is a code example of a bot you can talk too which has the ability of checking the weather, it has memory, it is using OpenAI functions, and it streams its outputs:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import json\nfrom typing import List, Literal, TypedDict\nfrom litechain import debug\n\nfrom litechain.contrib.llms.open_ai import (\n    OpenAIChatChain,\n    OpenAIChatDelta,\n    OpenAIChatMessage,\n)\n\n\nclass Memory(TypedDict):\n    history: List[OpenAIChatMessage]\n\n\nmemory = Memory(history=[])\n\n\nclass WeatherReturn(TypedDict):\n    location: str\n    forecast: str\n    temperature: str\n\n\ndef save_message_to_memory(message: OpenAIChatMessage) -> OpenAIChatMessage:\n    memory["history"].append(message)\n    return message\n\n\ndef update_delta_on_memory(delta: OpenAIChatDelta) -> OpenAIChatDelta:\n    if memory["history"][-1].role != delta.role and delta.role is not None:\n        memory["history"].append(\n            OpenAIChatMessage(role=delta.role, content=delta.content, name=delta.name)\n        )\n    else:\n        memory["history"][-1].content += delta.content\n    return delta\n\n\ndef weather_bot(user_input: str):\n    def reply_with_current_weather(\n        location: str, format: Literal["celsius", "fahrenheit"] = "celsius"\n    ):\n        """\n        Gets the current weather in a given location, use this function for any questions related to the weather\n\n        Parameters\n        ----------\n        location\n            The city to get the weather, e.g. San Francisco. Guess the location from user messages\n\n        format\n            A string with the full content of what the given role said\n        """\n\n        result = WeatherReturn(\n            location=location,\n            forecast="sunny",\n            temperature="25 C" if format == "celsius" else "77 F",\n        )\n\n        save_message_to_memory(\n            OpenAIChatMessage(\n                role="function",\n                content=json.dumps(result),\n                name="get_current_weather",\n            )\n        )\n\n        return weather_reply_chain(result)\n\n    weather_chain = debug(\n        OpenAIChatChain[str, OpenAIChatDelta](\n            "WeatherChain",\n            lambda user_input: [\n                *memory["history"],\n                save_message_to_memory(\n                    OpenAIChatMessage(role="user", content=user_input),\n                ),\n            ],\n            model="gpt-3.5-turbo-0613",\n            functions=[reply_with_current_weather],\n            temperature=0,\n        )\n    ).map(update_delta_on_memory)\n\n    weather_reply_chain = OpenAIChatChain[WeatherReturn, OpenAIChatDelta](\n        "WeatherReplyChain",\n        lambda weather: [\n            OpenAIChatMessage(role="user", content=user_input),\n            OpenAIChatMessage(\n                role="user",\n                content=f"Output from the weather system: {json.dumps(weather)}",\n            ),\n        ],\n        model="gpt-3.5-turbo-0613",\n        temperature=0,\n    )\n\n    return weather_chain(user_input)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from litechain.utils.chain import collect_final_output\n\n_ = await collect_final_output(weather_bot("hi there"))\n')),(0,r.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n    \n    > WeatherChain\n    \n    Assistant: Hello! How can I assist you today?\n"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'_ = await collect_final_output(weather_bot("is it hot today in Amsterdam?"))\n')),(0,r.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n    \n    > WeatherChain\n    \n    Function: reply_with_current_weather(location='Amsterdam')\n    \n    > WeatherReplyChain\n    \n    Assistant: Yes, it is hot today in Amsterdam with a temperature of 25 degrees Celsius and sunny weather.\n"))),(0,r.kt)("p",null,"The bot is working well, it replies chit-chat messages as well as calling the weather function when needed, and replying to the user in natural language."),(0,r.kt)("p",null,"Let's inspect what's inside the bot memory:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"memory['history']\n")),(0,r.kt)(c,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    [OpenAIChatMessage(role='user', content='hi there', name=None),\n     OpenAIChatMessage(role='assistant', content='Hello! How can I assist you today?', name=None),\n     OpenAIChatMessage(role='user', content='is it hot today in Amsterdam?', name=None),\n     OpenAIChatMessage(role='function', content='{\"location\": \"Amsterdam\", \"forecast\": \"sunny\", \"temperature\": \"25 C\"}', name='get_current_weather'),\n     OpenAIChatMessage(role='assistant', content='Yes, it is hot today in Amsterdam with a temperature of 25 degrees Celsius and sunny weather.', name=None)]\n"))),(0,r.kt)("p",null,"It saved both the conversation and the results of the function call, this way, continued conversations will be able to use the previous context, include the previous function result."),(0,r.kt)("p",null,"That's it, if you have any questions about this example, ",(0,r.kt)("a",{parentName:"p",href:"https://discord.gg/48ZM5KkKgw"},"join our discord community")," and we can help you out."),(0,r.kt)("p",null,"Also, if you are interested in running a bot like this inside a nice UI, check out our ",(0,r.kt)("a",{parentName:"p",href:"../ui/chainlit"},"docs on Chainlit"),"."))}d.isMDXComponent=!0}}]);