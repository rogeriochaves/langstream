"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4945],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>d});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",h={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=c(n),m=r,d=u["".concat(l,".").concat(m)]||u[m]||h[m]||o;return n?a.createElement(d,i(i({ref:t},p),{},{components:n})):a.createElement(d,i({ref:t},p))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:r,i[1]=s;for(var c=2;c<o;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},8130:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var a=n(7462),r=(n(7294),n(3905));const o={sidebar_position:1},i="Simple Bot with Weather Tool",s={unversionedId:"examples/weather-bot",id:"examples/weather-bot",title:"Simple Bot with Weather Tool",description:"Below is a code example of a bot you can talk too which has the ability of checking the weather, it has memory, it is using OpenAI functions, and it streams its outputs:",source:"@site/docs/examples/weather-bot.md",sourceDirName:"examples",slug:"/examples/weather-bot",permalink:"/litechain/docs/examples/weather-bot",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/examples/weather-bot.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Code Examples",permalink:"/litechain/docs/examples/"},next:{title:"Extracting Schema for OpenAI Functions",permalink:"/litechain/docs/examples/openai-function-call-extract-schema"}},l={},c=[],p=(u="CodeOutputBlock",function(e){return console.warn("Component "+u+" was not imported, exported, or provided by MDXProvider as global scope"),(0,r.kt)("div",e)});var u;const h={toc:c},m="wrapper";function d(e){let{components:t,...n}=e;return(0,r.kt)(m,(0,a.Z)({},h,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"simple-bot-with-weather-tool"},"Simple Bot with Weather Tool"),(0,r.kt)("p",null,"Below is a code example of a bot you can talk too which has the ability of checking the weather, it has memory, it is using OpenAI functions, and it streams its outputs:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'import json\nfrom typing import List, Literal, TypedDict\nfrom litechain import debug, as_async_generator\n\nfrom litechain.contrib.llms.open_ai import (\n    OpenAIChatChain,\n    OpenAIChatDelta,\n    OpenAIChatMessage,\n)\n\n\nclass Memory(TypedDict):\n    history: List[OpenAIChatMessage]\n\n\nmemory = Memory(history=[])\n\n\ndef save_message_to_memory(message: OpenAIChatMessage) -> OpenAIChatMessage:\n    memory["history"].append(message)\n    return message\n\n\ndef update_delta_on_memory(delta: OpenAIChatDelta) -> OpenAIChatDelta:\n    if memory["history"][-1].role != delta.role and delta.role is not None:\n        memory["history"].append(\n            OpenAIChatMessage(role=delta.role, content=delta.content, name=delta.name)\n        )\n    else:\n        memory["history"][-1].content += delta.content\n    return delta\n\n\ndef weather_bot(user_input: str):\n    def get_current_weather(\n        location: str, format: Literal["celsius", "fahrenheit"] = "celsius"\n    ) -> OpenAIChatDelta:\n        result = {\n            "location": location,\n            "forecast": "sunny",\n            "temperature": "25 C" if format == "celsius" else "77 F",\n        }\n\n        return OpenAIChatDelta(\n            role="function", name="get_current_weather", content=json.dumps(result)\n        )\n\n    weather_chain = (\n        debug(\n            OpenAIChatChain[str, OpenAIChatDelta](\n                "WeatherChain",\n                lambda user_input: [\n                    *memory["history"],\n                    save_message_to_memory(\n                        OpenAIChatMessage(role="user", content=user_input),\n                    ),\n                ],\n                model="gpt-3.5-turbo-0613",\n                functions=[\n                    {\n                        "name": "get_current_weather",\n                        "description": "Gets the current weather in a given location, use this function for any questions related to the weather",\n                        "parameters": {\n                            "type": "object",\n                            "properties": {\n                                "location": {\n                                    "description": "The city to get the weather, e.g. San Francisco. Guess the location from user messages",\n                                    "type": "string",\n                                },\n                                "format": {\n                                    "description": "A string with the full content of what the given role said",\n                                    "type": "string",\n                                    "enum": ("celsius", "fahrenheit"),\n                                },\n                            },\n                        },\n                        "required": ["location"],\n                    }\n                ],\n                temperature=0,\n            )\n        )\n        .map(\n            lambda delta: get_current_weather(**json.loads(delta.content))\n            if delta.role == "function" and delta.name == "get_current_weather"\n            else delta\n        )\n        .map(update_delta_on_memory)\n    )\n\n    function_reply_chain = debug(\n        OpenAIChatChain[None, OpenAIChatDelta](\n            "FunctionReplyChain",\n            lambda _: memory["history"],\n            model="gpt-3.5-turbo-0613",\n            temperature=0,\n        )\n    ).map(update_delta_on_memory)\n\n    chain = weather_chain.and_then(\n        lambda outputs: function_reply_chain(None)\n        if list(outputs)[-1].role == "function"\n        else as_async_generator(*outputs)\n    )\n\n    return chain(user_input)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'from litechain.utils.chain import collect_final_output\n\n_ = await collect_final_output(weather_bot("hi there"))\n')),(0,r.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    \n    \n    > WeatherChain\n    \n    Assistant: Hello! How can I assist you today?\n"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'_ = await collect_final_output(weather_bot("is it hot today in Amsterdam?"))\n')),(0,r.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'    \n    \n    > WeatherChain\n    \n    Function get_current_weather: {\n      "location": "Amsterdam"\n    }\n    \n    > FunctionReplyChain\n    \n    Assistant: Yes, it is hot today in Amsterdam. The current temperature is 25\xb0C and it is sunny.\n'))),(0,r.kt)("p",null,"The bot is working well, it replies chit-chat messages as well as calling the weather function when needed, and replying to the user in natural language."),(0,r.kt)("p",null,"Let's inspect what's inside the bot memory:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"memory['history']\n")),(0,r.kt)(p,{lang:"python",mdxType:"CodeOutputBlock"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"    [OpenAIChatMessage(role='user', content='hi there', name=None),\n     OpenAIChatMessage(role='assistant', content='Hello! How can I assist you today?', name=None),\n     OpenAIChatMessage(role='user', content='is it hot today in Amsterdam?', name=None),\n     OpenAIChatMessage(role='function', content='{\"location\": \"Amsterdam\", \"forecast\": \"sunny\", \"temperature\": \"25 C\"}', name='get_current_weather'),\n     OpenAIChatMessage(role='assistant', content='Yes, it is hot today in Amsterdam. The current temperature is 25\xb0C and it is sunny.', name=None)]\n"))),(0,r.kt)("p",null,"It saved both the conversation and the results of the function call, this way, continued conversations will be able to use the previous context, include the previous function result."),(0,r.kt)("p",null,"That's it, if you have any questions about this example, ",(0,r.kt)("a",{parentName:"p",href:"https://discord.gg/48ZM5KkKgw"},"join our discord community")," and we can help you out."),(0,r.kt)("p",null,"Also, if you are interested in running a bot like this inside a nice UI, check out our ",(0,r.kt)("a",{parentName:"p",href:"../ui/chainlit"},"docs on Chainlit"),"."))}d.isMDXComponent=!0}}]);