"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6653],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>d});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function s(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?s(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},s=Object.keys(e);for(a=0;a<s.length;a++)n=s[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(a=0;a<s.length;a++)n=s[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),m=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=m(e.components);return a.createElement(l.Provider,{value:t},e.children)},c="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},g=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,s=e.originalType,l=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),c=m(n),g=r,d=c["".concat(l,".").concat(g)]||c[g]||u[g]||s;return n?a.createElement(d,i(i({ref:t},p),{},{components:n})):a.createElement(d,i({ref:t},p))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var s=n.length,i=new Array(s);i[0]=g;var o={};for(var l in t)hasOwnProperty.call(t,l)&&(o[l]=t[l]);o.originalType=e,o[c]="string"==typeof e?e:r,i[1]=o;for(var m=2;m<s;m++)i[m]=n[m];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}g.displayName="MDXCreateElement"},8280:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>s,metadata:()=>o,toc:()=>m});var a=n(7462),r=(n(7294),n(3905));const s={sidebar_position:1},i="Chainlit Integration",o={unversionedId:"ui/chainlit",id:"ui/chainlit",title:"Chainlit Integration",description:"Chainlit is a UI that gives you a ChatGPT like interface for your streams, it is very easy to set up, it has a slick UI, and it allows you to visualize the intermediary steps, so it's great for development!",source:"@site/docs/ui/chainlit.md",sourceDirName:"ui",slug:"/ui/chainlit",permalink:"/langstream/docs/ui/chainlit",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/ui/chainlit.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"UI",permalink:"/langstream/docs/category/ui"},next:{title:"Code Examples",permalink:"/langstream/docs/examples/"}},l={},m=[],p={toc:m},c="wrapper";function u(e){let{components:t,...n}=e;return(0,r.kt)(c,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"chainlit-integration"},"Chainlit Integration"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/Chainlit/chainlit"},"Chainlit")," is a UI that gives you a ChatGPT like interface for your streams, it is very easy to set up, it has a slick UI, and it allows you to visualize the intermediary steps, so it's great for development!"),(0,r.kt)("p",null,"You can install it with:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"pip install chainlit\n")),(0,r.kt)("p",null,"Then since we have access to all intermediary steps in LangStream, integrating it with Chainlit is as easy as this:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from typing import Dict\nimport chainlit as cl\n\n@cl.on_message\nasync def on_message(message: str):\n    messages_map: Dict[str, cl.Message] = {}\n\n    async for output in stream(message):\n        if output.stream in messages_map:\n            cl_message = messages_map[output.stream]\n            await cl_message.stream_token(output.data.content)\n        else:\n            messages_map[output.stream] = cl.Message(\n                author=output.stream,\n                content=output.data.content,\n                indent=0 if output.final else 1,\n            )\n            await messages_map[output.stream].send()\n")),(0,r.kt)("p",null,"Here we are calling our stream, which is an ",(0,r.kt)("a",{parentName:"p",href:"pathname:///reference/langstream/contrib/index.html#langstream.contrib.OpenAIChatStream"},(0,r.kt)("inlineCode",{parentName:"a"},"OpenAIChatStream")),", creating a new message as soon as a stream outputs, and streaming it new content as it arrives. We also ",(0,r.kt)("inlineCode",{parentName:"p"},"indent")," the message to mark it as an intermediary step if the output is not ",(0,r.kt)("inlineCode",{parentName:"p"},"final"),"."),(0,r.kt)("p",null,"Using our emoji translator example from before, this is how it is going to look like:"),(0,r.kt)("video",{src:"/langstream/img/chainlit-demo.mp4",width:"100%",controls:!0,style:{padding:"8px 0 32px 0"}}),(0,r.kt)("p",null,"Here is the complete code for an integration example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python",metastring:'title="main.py"',title:'"main.py"'},'from typing import Dict, Iterable, List, Tuple, TypedDict\n\nimport chainlit as cl\n\nfrom langstream import debug\nfrom langstream.contrib import OpenAIChatStream, OpenAIChatDelta, OpenAIChatMessage\n\n\nclass Memory(TypedDict):\n    history: List[OpenAIChatMessage]\n\n\nmemory = Memory(history=[])\n\n\ndef save_message_to_memory(message: OpenAIChatMessage) -> OpenAIChatMessage:\n    memory["history"].append(message)\n    return message\n\n\ndef update_delta_on_memory(delta: OpenAIChatDelta) -> OpenAIChatDelta:\n    if memory["history"][-1].role != delta.role and delta.role is not None:\n        memory["history"].append(\n            OpenAIChatMessage(role=delta.role, content=delta.content)\n        )\n    else:\n        memory["history"][-1].content += delta.content\n    return delta\n\n\ntranslator_stream = OpenAIChatStream[Iterable[OpenAIChatDelta], OpenAIChatDelta](\n    "TranslatorStream",\n    lambda emoji_tokens: [\n        OpenAIChatMessage(\n            role="user",\n            content=f"Translate this emoji message {[token.content for token in emoji_tokens]} to plain english",\n        )\n    ],\n    model="gpt-4",\n)\n\nstream = (\n    debug(\n        OpenAIChatStream[str, OpenAIChatDelta](\n            "EmojiChatStream",\n            lambda user_message: [\n                *memory["history"],\n                save_message_to_memory(\n                    OpenAIChatMessage(\n                        role="user", content=f"{user_message}. Reply in emojis"\n                    )\n                ),\n            ],\n            model="gpt-3.5-turbo-0613",\n            temperature=0,\n        )\n    )\n    .map(update_delta_on_memory)\n    .and_then(debug(translator_stream))\n)\n\n@cl.on_message\nasync def on_message(message: str):\n    messages_map: Dict[str, Tuple[bool, cl.Message]] = {}\n\n    async for output in stream(message):\n        if "@" in output.stream and not output.final:\n            continue\n        if output.stream in messages_map:\n            sent, cl_message = messages_map[output.stream]\n            if not sent:\n                await cl_message.send()\n                messages_map[output.stream] = (True, cl_message)\n            await cl_message.stream_token(output.data.content)\n        else:\n            messages_map[output.stream] = (\n                False,\n                cl.Message(\n                    author=output.stream,\n                    content=output.data.content,\n                    indent=0 if output.final else 1,\n                ),\n            )\n')),(0,r.kt)("p",null,"You can run it with:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"chainlit run main.py -w\n")))}u.isMDXComponent=!0}}]);